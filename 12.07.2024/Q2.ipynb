{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2e10c9f-fc83-4452-8227-57f811387cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07130a0e-24b3-4c64-a55e-958c9495ea55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load housing dataset\n",
    "df = pd.read_csv('housing_prices.csv')\n",
    "\n",
    "# Preprocess the data\n",
    "# One-hot encode 'Location' column\n",
    "df = pd.get_dummies(df, columns=['Location'], drop_first=True)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('Price', axis=1)\n",
    "y = df['Price']\n",
    "\n",
    "# Normalize numerical inputs\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2442399d-326f-4df9-b895-7eabade4184b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build the FNN model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1)  # No activation function for output layer (linear activation)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aef8e786-3cd7-46be-b702-a39700497724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 108099903488.0000 - mse: 108099903488.0000 - val_loss: 228049682432.0000 - val_mse: 228049682432.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 108099854336.0000 - mse: 108099854336.0000 - val_loss: 228049584128.0000 - val_mse: 228049584128.0000\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 108099796992.0000 - mse: 108099796992.0000 - val_loss: 228049453056.0000 - val_mse: 228049453056.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 108099731456.0000 - mse: 108099731456.0000 - val_loss: 228049338368.0000 - val_mse: 228049338368.0000\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 108099674112.0000 - mse: 108099674112.0000 - val_loss: 228049223680.0000 - val_mse: 228049223680.0000\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 108099624960.0000 - mse: 108099624960.0000 - val_loss: 228049125376.0000 - val_mse: 228049125376.0000\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 108099567616.0000 - mse: 108099567616.0000 - val_loss: 228048994304.0000 - val_mse: 228048994304.0000\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 108099510272.0000 - mse: 108099510272.0000 - val_loss: 228048863232.0000 - val_mse: 228048863232.0000\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 108099461120.0000 - mse: 108099461120.0000 - val_loss: 228048732160.0000 - val_mse: 228048732160.0000\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 108099403776.0000 - mse: 108099403776.0000 - val_loss: 228048666624.0000 - val_mse: 228048666624.0000\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 108099338240.0000 - mse: 108099338240.0000 - val_loss: 228048535552.0000 - val_mse: 228048535552.0000\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 108099280896.0000 - mse: 108099280896.0000 - val_loss: 228048404480.0000 - val_mse: 228048404480.0000\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 108099231744.0000 - mse: 108099231744.0000 - val_loss: 228048322560.0000 - val_mse: 228048322560.0000\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 108099166208.0000 - mse: 108099166208.0000 - val_loss: 228048191488.0000 - val_mse: 228048191488.0000\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 108099108864.0000 - mse: 108099108864.0000 - val_loss: 228048060416.0000 - val_mse: 228048060416.0000\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 108099043328.0000 - mse: 108099043328.0000 - val_loss: 228047929344.0000 - val_mse: 228047929344.0000\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 108098985984.0000 - mse: 108098985984.0000 - val_loss: 228047814656.0000 - val_mse: 228047814656.0000\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 108098936832.0000 - mse: 108098936832.0000 - val_loss: 228047667200.0000 - val_mse: 228047667200.0000\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 108098871296.0000 - mse: 108098871296.0000 - val_loss: 228047552512.0000 - val_mse: 228047552512.0000\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 108098805760.0000 - mse: 108098805760.0000 - val_loss: 228047421440.0000 - val_mse: 228047421440.0000\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 108098723840.0000 - mse: 108098723840.0000 - val_loss: 228047290368.0000 - val_mse: 228047290368.0000\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 108098674688.0000 - mse: 108098674688.0000 - val_loss: 228047126528.0000 - val_mse: 228047126528.0000\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 108098592768.0000 - mse: 108098592768.0000 - val_loss: 228046995456.0000 - val_mse: 228046995456.0000\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 108098527232.0000 - mse: 108098527232.0000 - val_loss: 228046831616.0000 - val_mse: 228046831616.0000\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 108098461696.0000 - mse: 108098461696.0000 - val_loss: 228046700544.0000 - val_mse: 228046700544.0000\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 108098379776.0000 - mse: 108098379776.0000 - val_loss: 228046536704.0000 - val_mse: 228046536704.0000\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 108098314240.0000 - mse: 108098314240.0000 - val_loss: 228046372864.0000 - val_mse: 228046372864.0000\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 108098224128.0000 - mse: 108098224128.0000 - val_loss: 228046192640.0000 - val_mse: 228046192640.0000\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 108098150400.0000 - mse: 108098150400.0000 - val_loss: 228046028800.0000 - val_mse: 228046028800.0000\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 108098068480.0000 - mse: 108098068480.0000 - val_loss: 228045864960.0000 - val_mse: 228045864960.0000\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 108097986560.0000 - mse: 108097986560.0000 - val_loss: 228045701120.0000 - val_mse: 228045701120.0000\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 108097888256.0000 - mse: 108097888256.0000 - val_loss: 228045488128.0000 - val_mse: 228045488128.0000\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 108097798144.0000 - mse: 108097798144.0000 - val_loss: 228045307904.0000 - val_mse: 228045307904.0000\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 108097708032.0000 - mse: 108097708032.0000 - val_loss: 228045094912.0000 - val_mse: 228045094912.0000\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 108097601536.0000 - mse: 108097601536.0000 - val_loss: 228044881920.0000 - val_mse: 228044881920.0000\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 108097503232.0000 - mse: 108097503232.0000 - val_loss: 228044701696.0000 - val_mse: 228044701696.0000\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 108097396736.0000 - mse: 108097396736.0000 - val_loss: 228044505088.0000 - val_mse: 228044505088.0000\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 108097298432.0000 - mse: 108097298432.0000 - val_loss: 228044259328.0000 - val_mse: 228044259328.0000\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 108097208320.0000 - mse: 108097208320.0000 - val_loss: 228044046336.0000 - val_mse: 228044046336.0000\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 108097077248.0000 - mse: 108097077248.0000 - val_loss: 228043800576.0000 - val_mse: 228043800576.0000\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 108096970752.0000 - mse: 108096970752.0000 - val_loss: 228043538432.0000 - val_mse: 228043538432.0000\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 108096847872.0000 - mse: 108096847872.0000 - val_loss: 228043325440.0000 - val_mse: 228043325440.0000\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 108096724992.0000 - mse: 108096724992.0000 - val_loss: 228043030528.0000 - val_mse: 228043030528.0000\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 108096593920.0000 - mse: 108096593920.0000 - val_loss: 228042784768.0000 - val_mse: 228042784768.0000\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 108096462848.0000 - mse: 108096462848.0000 - val_loss: 228042539008.0000 - val_mse: 228042539008.0000\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 108096323584.0000 - mse: 108096323584.0000 - val_loss: 228042244096.0000 - val_mse: 228042244096.0000\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 108096192512.0000 - mse: 108096192512.0000 - val_loss: 228041932800.0000 - val_mse: 228041932800.0000\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 108096053248.0000 - mse: 108096053248.0000 - val_loss: 228041654272.0000 - val_mse: 228041654272.0000\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 108095905792.0000 - mse: 108095905792.0000 - val_loss: 228041359360.0000 - val_mse: 228041359360.0000\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 108095758336.0000 - mse: 108095758336.0000 - val_loss: 228041031680.0000 - val_mse: 228041031680.0000\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mse'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "855ed3e2-a096-453b-9029-cc4dfda6bdfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 96195518464.0000 - mse: 96195518464.0000\n",
      "Test Mean Squared Error: 96195518464.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_mse = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f'Test Mean Squared Error: {test_mse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "85f1b752-2daa-4972-8aae-9b44bd8ee3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
      "Predicted Price: $3.44\n"
     ]
    }
   ],
   "source": [
    "# Predicting on new data (example)\n",
    "# Assume new_data is already prepared and scaled as in the previous example\n",
    "\n",
    "new_data = np.array([[3, 2, 1500, 10, 0, 1]])  # Example input (3 bedrooms, 2 bathrooms, 1500 sqft, Urban, 10 years old)\n",
    "new_data_scaled = scaler.transform(new_data)\n",
    "\n",
    "# Make predictions using the trained model\n",
    "prediction = model.predict(new_data_scaled)\n",
    "print(f'Predicted Price: ${prediction[0][0]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad563853-3c9f-43a5-b81f-05ebc247a2c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2867d0-68ce-4bf3-91c0-5152f7f26859",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
